{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('base': conda)",
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3c8c3a880c14b61cd710572e2ac6298335c33509b1f7d3900bc107f98e9cc647"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Hyperparameter Optimization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "With great models , comes the great problem of optimizing hyperparameters to get the best scoring model. So, **what is this hyperparameters optimization?**\n",
    "Suppose there is a simple pipeline for your machine learning project. there is a dataset, you directly apply a model, and then you have results. The parameters that the model has here are know as hyper-parameters, i.e. the parameters that control the training/fitting process of the model.\n",
    "So, **how would you find the best parameters?**\n",
    "A methos swould be to evaluate all the combinations and see which one improves the metric.\n",
    "\n",
    "let's look at the random forest model from scikit-learn."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion=\"gini\", \n",
    "    max_depth=None, \n",
    "    min_samples_split=2, \n",
    "    min_samples_leaf=1, \n",
    "    min_weight_fraction_leaf=0., \n",
    "    max_features=\"auto\", \n",
    "    max_leaf_nodes=None, \n",
    "    min_impurity_decrease=0., \n",
    "    min_impurity_split=None, \n",
    "    bootstrap=True, \n",
    "    oob_score=False, \n",
    "    n_jobs=None, \n",
    "    random_state=None, \n",
    "    verbose=0, \n",
    "    warm_start=False, \n",
    "    class_weight=None, \n",
    "    ccp_alpha=0.0, \n",
    "    max_samples=None)\n",
    ")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "There are nineteen parameters, and all the combinations of all these paramters for all the values they can assume are going to be infinite. Normally, we don't have the resource and time to do this. Thus, we specify a *grid* of parameters . A search over this grid to find the best combination of parameters is know as **grid search** . we can say the *\"n_estimator\"* can be 100, 250, 300, 500; *\"max_depth\"* can be 1,2,5,7,11,15 and *\"criterion\"* can be \"gini\" or \"entropy\". These may not look like a lot of parameters but it would take a lot of times for computationif the dataset is too large.\n",
    "Grid search is not very popular. let's look at how it is done with an example of **predicting mobile phone price range** given the specifications."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   battery_power  blue  clock_speed  ...  touch_screen  wifi  price_range\n0            842     0          2.2  ...             0     1            1\n1           1021     1          0.5  ...             1     0            2\n2            563     1          0.5  ...             1     0            2\n3            615     1          2.5  ...             0     0            2\n4           1821     1          1.2  ...             1     0            1\n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>battery_power</th>\n      <th>blue</th>\n      <th>clock_speed</th>\n      <th>dual_sim</th>\n      <th>fc</th>\n      <th>four_g</th>\n      <th>int_memory</th>\n      <th>m_dep</th>\n      <th>mobile_wt</th>\n      <th>n_cores</th>\n      <th>pc</th>\n      <th>px_height</th>\n      <th>px_width</th>\n      <th>ram</th>\n      <th>sc_h</th>\n      <th>sc_w</th>\n      <th>talk_time</th>\n      <th>three_g</th>\n      <th>touch_screen</th>\n      <th>wifi</th>\n      <th>price_range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842</td>\n      <td>0</td>\n      <td>2.2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0.6</td>\n      <td>188</td>\n      <td>2</td>\n      <td>2</td>\n      <td>20</td>\n      <td>756</td>\n      <td>2549</td>\n      <td>9</td>\n      <td>7</td>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1021</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>53</td>\n      <td>0.7</td>\n      <td>136</td>\n      <td>3</td>\n      <td>6</td>\n      <td>905</td>\n      <td>1988</td>\n      <td>2631</td>\n      <td>17</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>563</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41</td>\n      <td>0.9</td>\n      <td>145</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1263</td>\n      <td>1716</td>\n      <td>2603</td>\n      <td>11</td>\n      <td>2</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>615</td>\n      <td>1</td>\n      <td>2.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.8</td>\n      <td>131</td>\n      <td>6</td>\n      <td>9</td>\n      <td>1216</td>\n      <td>1786</td>\n      <td>2769</td>\n      <td>16</td>\n      <td>8</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1821</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>0</td>\n      <td>13</td>\n      <td>1</td>\n      <td>44</td>\n      <td>0.6</td>\n      <td>141</td>\n      <td>2</td>\n      <td>14</td>\n      <td>1208</td>\n      <td>1212</td>\n      <td>1411</td>\n      <td>8</td>\n      <td>2</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('dataset/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2000, 21)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "source": [
    "we have 20 features and 2000 samples and a range of price which has 4 categories from 0 to 3. we can easily use strtified kfold and accuracy as a metric to evaluate.\n",
    "let's create a python file **rf_grid_search.py**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In the end, we see that our best five fold accuracy score was 0.889, and we have the best parameters from our grid search. Next best thing that we can use is random search. In **random search**, we randomly select a combination of parameters and calculate the cross-validation score. The time consumed here is less than grid search because we do not evaluate over all different combinations of parameters. we choose how many times we want to evaluate our models, and that's what decides how much time the search takes, We use **RandomizeSearchCV** . let's create a python file **rf_random_search.py**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Random searrch is faster than grid search if the number of iterations is less. Using these two, we can find the optimal parameters for all kind of models as long as they have a fit and predict function, which is the standard of scikit-learn.\n",
    "\n",
    "Sometimes, we might want to use a pipeline. For example , let's say that we are dealing with a multiclass classification problem. In this problem, the training data consists of two text columns , and we are required to build a model to predict the calss. Let's assume that the pipeline you choose is to first apply tf-idf in a semi supervised manner and then use SVD with SVM classifier. Now , the problem is we have to select  the components of SVD and also need to tune the parameters of SVM. How to do this ? Let's build a python file **pipline_search.py**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The pipeline show in the python file **pipeline_search.py** has SVD (singular value decomposition) , standard scaling and an SVM (support vector machine) model. please note that we won't be able to run the above code since we don't have data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Advance Hyperparameter Optimization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "When we go into Advance hyperparameters optimization techniques, we can take a look at **minimization of functions** using different kinds of minimization algorithms. This can be achieved by using many minimization functions such as :\n",
    "- Downhill simplex algorithms\n",
    "- Nelder-Mead optimization\n",
    "- Bayesian technique with Gaussian process for finding optimal parameters\n",
    "- Genetic algorithms\n",
    "\n",
    "let's see how the Gaussian process can be used for hyperparameters optimization . These kinds of algorithms need a function they can optimize. Most of the time , it's about the minimization of this funtion, like we **minimiza loss**\n",
    "\n",
    "So, let's say, we want to find the best parameters for best accuracy and obiously , the more the accuracy is better. Now we cannot minimize the accuracy , but we can minimize it when we multiply it by -1. this way, we are minimizing the negative of accuracy, but in fact we are maximizing accuracy. Using **Bayesian optimization with Gaussian process** can be accomplished by using **gp_minimize** function from scikit-learn (skopt) libaray. \n",
    "Let's take a look at how we can tune the parameters of our random forest model using this function.\n",
    "\n",
    "we will be creating a python file **rf_gp_minimize.py**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}